<h1 align = "center"> PERSISTENCIA DE MODELOS EN PYTHON </h1> 

<p align = "center">
  <img src = "media/portada_persistencia.png"/>
</p>
<p align = "center">
  <a href = "https://github.com/sarapazr04">
    <img src = "https://img.shields.io/badge/-sarapazr04-181717?style=for-the-badge&logo=github&logoColor=white" alt =  "GitHub: youssef-nabaha" />
  </a>
</p>

## √çNDICE

1. **Conceptos Fundamentales:**  
   - Qu√© significa persistir objetos en Python  
   - Serializaci√≥n y deserializaci√≥n de modelos  
   - Persistencia en modelos de regresi√≥n lineal  

2. **M√©todos de Persistencia:**  
   - `pickle`  
   - `joblib`  
   - `dill`  
   - `skops`  

3. **Prueba de Persistencia:**  
   - Ejemplo con c√≥digo 
   - Comparaci√≥n de resultados y tiempos  

4. **Gu√≠a de Implementaci√≥n:**  
   - Pasos para guardar y cargar modelos  
   - Funciones `save_model()` y `load_model()`  

5. **Referencias y Recursos:**  

## 1. CONCEPTOS FUNDAMENTALES
### 1.1. ¬øQu√© significa persistir objetos en Python?

La **persistencia** en programaci√≥n hace referencia a la capacidad de **guardar el estado de un objeto** para poder **recuperarlo m√°s adelante** y continuar utiliz√°ndolo sin necesidad de volver a crearlo o entrenarlo.

En Python, este proceso se consigue mediante la **serializaci√≥n**, que convierte el objeto en una secuencia de bytes que puede almacenarse en disco o transmitirse por red.

- **Definici√≥n formal:**  
> La persistencia es el proceso de **almacenar el estado de un objeto** en un formato que permita **reconstruirlo exactamente igual** en el futuro.

- **Ejemplo b√°sico:**

```python
# Guardar una lista en un archivo con pickle
import pickle

data = [1, 2, 3, 4, 5]

# Serializar (guardar)
with open("datos.pkl", "wb") as f:
    pickle.dump(data, f)

# Deserializar (cargar)
with open("datos.pkl", "rb") as f:
    cargado = pickle.load(f)

print(cargado)   # [1, 2, 3, 4, 5]
```
>En este ejemplo, el objeto `data` se convierte en bytes y se guarda en el archivo `datos.pkl`.  
>M√°s tarde puede cargarse para recuperar su estado original, incluso despu√©s de reiniciar el programa.

### 1.2. Serializaci√≥n y deserializaci√≥n de modelos

La **serializaci√≥n** convierte un objeto de Python (por ejemplo, un modelo de regresi√≥n) en un formato que puede almacenarse en un archivo `.pkl` o `.joblib`.

La **deserializaci√≥n** es el proceso inverso: reconstruir el objeto a partir del archivo guardado.

---

#### Esquema general:
Modelo entrenado ‚Üí Serializaci√≥n ‚Üí Archivo guardado (.pkl / .joblib)

Archivo guardado ‚Üí Deserializaci√≥n ‚Üí Modelo recuperado

### 1.3. Persistencia en modelos de regresi√≥n lineal

Cuando entrenamos un modelo de **regresi√≥n lineal** (simple o m√∫ltiple), este aprende una serie de **par√°metros internos** que describen la relaci√≥n entre las variables de entrada y salida.

| Par√°metro | Descripci√≥n |
|------------|--------------|
| `coef_` | Coeficientes (pendientes) asociados a cada variable independiente |
| `intercept_` | T√©rmino independiente o sesgo |
| `n_features_in_` | N√∫mero de variables de entrada |

Guardar el modelo consiste en **almacenar todos estos valores** para poder reproducir exactamente la funci√≥n aprendida sin volver a entrenar.

---

#### - Ejemplo conceptual:

> Y = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑X‚ÇÅ + Œ≤‚ÇÇ¬∑X‚ÇÇ + ‚Ä¶ + Œ≤‚Çô¬∑X‚Çô

Si el modelo aprende:

> Œ≤‚ÇÄ = 1.2,  Œ≤‚ÇÅ = 0.8,  Œ≤‚ÇÇ = 2.5

estos valores se guardan dentro del archivo serializado, garantizando que el modelo podr√° volver a utilizarse en cualquier momento sin p√©rdida de informaci√≥n.

#### - Ventajas principales de la persistencia de modelos:

- **Ahorro de tiempo:** no es necesario reentrenar el modelo cada vez.  
- **Reutilizaci√≥n:** los modelos pueden usarse en otras aplicaciones o sistemas.  
- **Reproducibilidad:** los resultados se mantienen id√©nticos al entrenamiento original.  
- **Versionado:** permite guardar distintas versiones del mismo modelo entrenado.

## 2. M√âTODOS DE PERSISTENCIA

### 2.1. [pickle](https://docs.python.org/3/library/pickle.html)

> **Descripci√≥n:** Biblioteca est√°ndar de Python para serializar y deserializar objetos.  
> Convierte cualquier objeto de Python en una secuencia de bytes para poder almacenarlo o transmitirlo.

- **Instalaci√≥n:**
  
  `pickle` viene incluido en Python, **no requiere instalaci√≥n adicional.**

- **Uso b√°sico:**

    ```python
    import pickle

    # Guardar un objeto
    with open("modelo.pkl", "wb") as f:
        pickle.dump(modelo, f)

    # Cargar el objeto
    with open("modelo.pkl", "rb") as f:
        modelo_cargado = pickle.load(f)
    ```

- **Ventajas:**

    - Incluido por defecto en Python.
    - Muy f√°cil de usar.
    - Permite guardar casi cualquier tipo de objeto.
    - Ideal para proyectos peque√±os o prototipos.

- **Desventajas:**

    - Archivos m√°s grandes que otros m√©todos.
    - M√°s lento con grandes vol√∫menes de datos.
    - **Poco seguro**: cargar un archivo `pickle` desconocido puede ejecutar c√≥digo malicioso.
    - No est√° optimizado para objetos de NumPy o modelos de `scikit-learn`.
- **Cu√°ndo usar:**

    - Prototipos simples o educativos.
    - Casos donde la seguridad no es cr√≠tica.
    - Cuando se requiere una soluci√≥n nativa sin dependencias externas.

### 2.2. [joblib](https://joblib.readthedocs.io/en/latest/)

> **Descripci√≥n:** Biblioteca optimizada para guardar objetos grandes, especialmente aquellos que contienen arrays NumPy (como los modelos de scikit-learn).

- **Instalaci√≥n:**

    `pip install joblib`

- **Uso b√°sico:**

    ``` python
    import joblib
    from sklearn.linear_model import LinearRegression

    # Entrenar y guardar el modelo
    modelo = LinearRegression().fit(X, y)
    joblib.dump(modelo, "modelo.joblib")

    # Cargar el modelo
    modelo_cargado = joblib.load("modelo.joblib") 
    ```

- **Ventajas:**
  - Mucho m√°s eficiente que `pickle` para modelos de *scikit-learn*.  
  - Compresi√≥n integrada (`compress=3`).  
  - Ideal para grandes *datasets* o modelos complejos.  
  - Est√°ndar de facto para persistencia en *machine learning*.

- **Desventajas:**
  - Necesita instalaci√≥n adicional (`joblib`).  
  - No a√±ade seguridad extra frente a `pickle` (misma advertencia).  
  - Ligera dependencia de versi√≥n de librer√≠as.

- **Cu√°ndo usar:**
  - **Modelos de regresi√≥n lineal** (simple o m√∫ltiple).  
  - Proyectos que utilicen *scikit-learn*.  
  - Cuando se requiere **eficiencia y portabilidad**.

### 2.3. [dill](https://pypi.org/project/dill/)

> **Descripci√≥n:** Extensi√≥n avanzada de `pickle` que permite serializar objetos que pickle no puede manejar (funciones, lambdas, cierres, etc.).

- **Instalaci√≥n:**

    `pip install dill`

- **Uso b√°sico:**

    ``` python
    import dill

    # Guardar un objeto complejo
    with open("modelo.dill", "wb") as f:
        dill.dump(modelo, f)

    # Cargarlo
    with open("modelo.dill", "rb") as f:
        modelo_cargado = dill.load(f)
    ```

- **Ventajas:**
  - Puede guardar objetos m√°s complejos que pickle. 
  - Compatible con casi cualquier estructura de Python. 
  - Misma sintaxis que pickle.

- **Desventajas:**
  - Archivos m√°s grandes. 
  - No mejora el rendimiento respecto a joblib. 
  - No est√° pensada espec√≠ficamente para machine learning.

- **Cu√°ndo usar:**
  - Cuando se necesitan guardar objetos complejos (funciones o clases personalizadas).
  - No recomendable para modelos de regresi√≥n lineal, salvo casos espec√≠ficos.

### 2.4. [skops](https://skops.readthedocs.io/en/stable/)

> **Descripci√≥n:** Biblioteca moderna desarrollada por el equipo de *scikit-learn* para guardar modelos de forma **segura y reproducible**.  
> Usa un formato legible (*JSON + binarios*) que evita los riesgos de `pickle`.

- **Instalaci√≥n:**

    `pip install skops`

- **Uso b√°sico:**

    ``` python
    from skops.io import dump, load

    # Guardar el modelo
    dump(modelo, "modelo.skops")

    # Cargar el modelo
    modelo_cargado = load("modelo.skops")
    ```

- **Ventajas:**
  - Mayor seguridad (no ejecuta c√≥digo al cargar).  
  - Archivos portables y legibles.  
  - Creada espec√≠ficamente para modelos de *scikit-learn*.  
  - Evita problemas de compatibilidad entre versiones.

- **Desventajas:**
  - M√°s nueva y menos extendida.  
  - No soporta a√∫n todos los tipos de objetos.  
  - Ligera curva de aprendizaje inicial.

- **Cu√°ndo usar:**
  - Proyectos que requieran **persistencia segura y reproducible**.  
  - Escenarios donde el modelo vaya a compartirse o publicarse.  
  - Ideal para **trabajos acad√©micos o producci√≥n segura**.

### Comparativa de los m√©todos de persistencia

| M√©todo | Eficiencia (velocidad / tama√±o) | Adecuado para regresi√≥n lineal | Compatibilidad y facilidad de uso |
|:--------|:---------------------------------|:--------------------------------|:----------------------------------|
| **pickle** | üü° Media ‚Äì Archivos m√°s grandes y lentos con arrays grandes | üü° V√°lido, pero no optimizado para `scikit-learn` | üü¢ Muy f√°cil (nativo en Python) |
| **joblib** | üü¢ Alta ‚Äì R√°pido y archivos m√°s compactos (especialmente con `compress`) | üü¢ **Ideal** para modelos de `scikit-learn` y grandes datasets | üü¢ Sencillo y ampliamente usado en ML |
| **dill** | üü° Media ‚Äì Similar a pickle, pero permite objetos m√°s complejos | üî¥ Poco recomendable para regresi√≥n lineal (no optimiza arrays) | üü° F√°cil de usar, pero menos com√∫n |
| **skops** | üü¢ Alta ‚Äì Buen rendimiento y formato compacto en JSON/binario | üü¢ Muy adecuado, dise√±ado para `scikit-learn` | üü° M√°s reciente, requiere familiarizaci√≥n inicial |

> **Conclusi√≥n:**  
> - **`joblib`** es el m√©todo **m√°s eficiente y adecuado** para guardar modelos de regresi√≥n lineal de *scikit-learn*.  
> - **`skops`** destaca como alternativa moderna y **m√°s segura**, ideal si el modelo va a compartirse o publicarse.  
> - **`pickle`** es funcional pero menos eficiente.  
> - **`dill`** es √∫til solo cuando se requiere guardar objetos Python muy complejos.


## 3. PRUEBA DE PERSISTENCIA

### 3.1. Ejemplo con c√≥digo (Regresi√≥n Lineal M√∫ltiple)

 En este ejemplo realizaremos una **prueba b√°sica de persistencia** para comprobar que un modelo de regresi√≥n lineal puede guardarse y cargarse correctamente sin perder su capacidad de predicci√≥n.  
 Usaremos un peque√±o dataset sint√©tico con dos variables independientes (`X‚ÇÅ`, `X‚ÇÇ`) y una dependiente (`y`).

```python
import numpy as np
from sklearn.linear_model import LinearRegression
import joblib

# 1. Crear datos simulados (regresi√≥n m√∫ltiple)
X = np.array([
    [1, 2],
    [2, 3],
    [3, 4],
    [4, 5],
    [5, 6]
])
y = np.array([5, 8, 11, 14, 17])  # y = 1 + 2*X1 + X2

# 2Ô∏è. Entrenar modelo
modelo = LinearRegression()
modelo.fit(X, y)

# Mostrar par√°metros aprendidos
print("Coeficientes (Œ≤‚ÇÅ, Œ≤‚ÇÇ):", modelo.coef_)
print("Intercepto (Œ≤‚ÇÄ):", modelo.intercept_)

# 3. Guardar el modelo (serializaci√≥n)
joblib.dump(modelo, "modelo_persistente.joblib")

# 4. Cargar el modelo (deserializaci√≥n)
modelo_cargado = joblib.load("modelo_persistente.joblib")

# 5. Verificar que el modelo funciona igual
X_nuevo = np.array([[6, 7]])
pred_original = modelo.predict(X_nuevo)
pred_cargado = modelo_cargado.predict(X_nuevo)

print("\nPredicci√≥n original:", pred_original)
print("Predicci√≥n tras cargar modelo:", pred_cargado)

# 6. Comprobaci√≥n de equivalencia
assert np.allclose(pred_original, pred_cargado), "Error: los resultados no coinciden"
print("\n El modelo cargado produce las mismas predicciones que el original.")
```
### **Salida:**
```
Coeficientes (Œ≤‚ÇÅ, Œ≤‚ÇÇ): [1. 2.]
Intercepto (Œ≤‚ÇÄ): 1.0

Predicci√≥n original: [20.]
Predicci√≥n tras cargar modelo: [20.]

El modelo cargado produce las mismas predicciones que el original.
```

### **Interpretaci√≥n de la prueba**

- **Entrenamiento:**  
  El modelo aprende una relaci√≥n lineal entre las variables:  
  `y = 1 + 1¬∑X‚ÇÅ + 2¬∑X‚ÇÇ`

- **Guardado y carga:**  
  El modelo se serializa con `joblib.dump()` y se recupera con `joblib.load()`.  
  Ambos objetos (el original y el cargado) producen **predicciones id√©nticas**, lo que demuestra que la persistencia fue exitosa.

- **Comprobaci√≥n autom√°tica:**  
  La instrucci√≥n `assert np.allclose(pred_original, pred_cargado)` confirma que **no existe diferencia num√©rica** entre ambos resultados.

### **Comparaci√≥n de m√©todos y tiempos**

Para comparar la eficiencia entre `pickle` y `joblib`, se puede a√±adir una peque√±a medici√≥n de tiempo y tama√±o del archivo:

```python
import time, os, pickle

# Guardar con pickle
t0 = time.perf_counter()
with open("modelo.pkl", "wb") as f:
    pickle.dump(modelo, f)
pickle_time = time.perf_counter() - t0
pickle_size = os.path.getsize("modelo.pkl")

# Guardar con joblib
t0 = time.perf_counter()
joblib.dump(modelo, "modelo.joblib", compress=3)
joblib_time = time.perf_counter() - t0
joblib_size = os.path.getsize("modelo.joblib")

print(f"\nTiempo pickle: {pickle_time:.6f}s, tama√±o: {pickle_size/1024:.2f} KB")
print(f"Tiempo joblib: {joblib_time:.6f}s, tama√±o: {joblib_size/1024:.2f} KB")
```

> **Resultado esperado:**  
> `joblib` suele generar **archivos m√°s peque√±os** y **guardar/cargar m√°s r√°pido** que `pickle`, especialmente con modelos que contienen arrays de *NumPy* (como los coeficientes de una regresi√≥n).

---

### **Conclusi√≥n de la prueba**

- El modelo entrenado se guarda y recupera correctamente usando `joblib`.  
- Las predicciones antes y despu√©s del guardado son **id√©nticas**.  
- Se confirma que la **persistencia de modelos funciona correctamente** para la regresi√≥n lineal m√∫ltiple.  
- `joblib` se muestra como la opci√≥n **m√°s eficiente y confiable** para esta tarea, cumpliendo as√≠ con los criterios de la historia de usuario.

## 4. GU√çA PARA IMPLEMENTAR EN LA APLICACI√ìN

### 4.1. Pasos para guardar y cargar modelos

> En esta secci√≥n se documenta el **proceso completo** que el equipo debe seguir para **guardar y recuperar modelos de regresi√≥n lineal** dentro de la aplicaci√≥n.  
> Los pasos son v√°lidos tanto para modelos simples como m√∫ltiples entrenados con *scikit-learn*.

---

#### **1. Entrenar el modelo**

Primero se entrena el modelo con los datos seleccionados:

```python
from sklearn.linear_model import LinearRegression

X = [[1, 2], [2, 3], [3, 4], [4, 5]]
y = [5, 8, 11, 14]

modelo = LinearRegression().fit(X, y)
```

>El modelo aprende los coeficientes (`coef_`) y el intercepto (`intercept_`) que definen la funci√≥n lineal de predicci√≥n.

#### **2. Guardar el modelo entrenado**

Una vez entrenado, el modelo debe guardarse para poder reutilizarlo posteriormente sin volver a entrenar.

El m√©todo recomendado es `joblib.`

```python
import joblib

# Guardar el modelo en un archivo
joblib.dump(modelo, "modelos/regresion_lineal.joblib")
```

> El archivo `.joblib` contiene todos los par√°metros aprendidos del modelo, listos para recuperarse en otra sesi√≥n o equipo.

#### **3. Cargar el modelo guardado**

Para usar un modelo ya entrenado y guardado, basta con cargarlo desde el archivo:

```python
# Cargar el modelo desde disco
modelo_cargado = joblib.load("modelos/regresion_lineal.joblib")

# Verificar que funciona correctamente
print(modelo_cargado.predict([[5, 6]]))
```

>El modelo cargado conserva su comportamiento y predice de la misma manera que el original.
Esto permite mantener la consistencia del sistema incluso tras cerrar la aplicaci√≥n.

#### **4. Verificaci√≥n del proceso**

Se recomienda siempre comprobar que el modelo cargado produce las mismas predicciones que el original:

```python
import numpy as np

pred_original = modelo.predict([[5, 6]])
pred_cargado = modelo_cargado.predict([[5, 6]])

assert np.allclose(pred_original, pred_cargado), "Error: los modelos no coinciden"
```

>Si la comprobaci√≥n es correcta, la persistencia de modelos est√° funcionando adecuadamente.

### 4.2. Propuesta de funciones `save_model()` y `load_model()`

A continuaci√≥n se proponen dos funciones gen√©ricas para integrar la persistencia de modelos dentro de la aplicaci√≥n de regresi√≥n lineal.
Estas funciones permiten guardar y cargar cualquier modelo de manera uniforme y reutilizable por todo el equipo.

#### Funci√≥n `save_model()`

```python
import joblib
from pathlib import Path
from datetime import datetime

def save_model(model, file_path="modelos/modelo.joblib", compress=3):
    """
    Guarda un modelo entrenado en un archivo .joblib.
    Par√°metros:
        model: objeto del modelo entrenado (ej. LinearRegression)
        file_path: ruta donde se guardar√° el archivo
        compress: nivel de compresi√≥n (por defecto 3)
    """
    path = Path(file_path)
    path.parent.mkdir(parents=True, exist_ok=True)
    joblib.dump(model, path, compress=compress)
    
    print(f"Modelo guardado correctamente en {path}")
    print(f"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
```

#### Funci√≥n `load_model()`

```python
import joblib
from pathlib import Path

def load_model(file_path="modelos/modelo.joblib"):
    """
    Carga un modelo previamente guardado con joblib.
    Par√°metros:
        file_path: ruta del archivo del modelo (.joblib)
    Retorna:
        model: objeto del modelo cargado listo para predecir
    """
    path = Path(file_path)
    if not path.exists():
        raise FileNotFoundError(f"‚ùå El archivo {file_path} no existe.")
    
    model = joblib.load(path)
    print(f"Modelo cargado correctamente desde {path}")
    return model
```

#### Ejemplo de uso conjunto:

```python
# Entrenar y guardar
modelo = LinearRegression().fit(X, y)
save_model(modelo, "modelos/regresion_multiple.joblib")

# Cargar el modelo m√°s adelante
modelo_recuperado = load_model("modelos/regresion_multiple.joblib")

# Comprobar que funciona igual
print(modelo_recuperado.predict([[5, 6]]))
```

> Estas funciones facilitan la integraci√≥n de la persistencia dentro de la interfaz gr√°fica o los flujos de backend del proyecto, asegurando un proceso est√°ndar, r√°pido y reproducible para todo el equipo.

## 5. REFERENCIAS Y RECURSOS

### 5.1. Documentaci√≥n Oficial

1. **pickle (Python Standard Library):**  
   - https://docs.python.org/3/library/pickle.html  
   - M√≥dulo est√°ndar para serializaci√≥n y deserializaci√≥n de objetos.

2. **joblib:**  
   - https://joblib.readthedocs.io/en/latest/  
   - Biblioteca optimizada para persistencia de modelos y arrays de NumPy.

3. **dill:**  
   - https://pypi.org/project/dill/  
   - Extensi√≥n de `pickle` para objetos complejos y funciones personalizadas.

4. **skops:**  
   - https://skops.readthedocs.io/en/stable/  
   - Proyecto del equipo de *scikit-learn* que permite guardar modelos de forma segura y reproducible.

5. **scikit-learn:**  
   - https://scikit-learn.org/stable/modules/model_persistence.html  
   - Gu√≠a oficial sobre c√≥mo guardar y cargar modelos con `joblib` y `pickle`.

---

### 5.2. Tutoriales y Blogs Recomendados

1. **Real Python ‚Äì Model Persistence with joblib and pickle**  
   - https://realpython.com/python-pickle-module/  
   - Explicaci√≥n clara de c√≥mo usar `pickle` y `joblib` para guardar modelos.

2. **Machine Learning Mastery ‚Äì Save and Load Machine Learning Models in Python**  
   - https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/  
   - Ejemplos pr√°cticos de persistencia con `scikit-learn`.

3. **Towards Data Science ‚Äì Safe Model Saving with skops**  
   - https://towardsdatascience.com/safely-saving-your-scikit-learn-models-with-skops-39d6486574b6  
   - Introducci√≥n al nuevo m√©todo de guardado seguro con `skops`.

4. **DataCamp ‚Äì Serialization in Python**  
   - https://www.datacamp.com/tutorial/pickle-python-tutorial  
   - Tutorial paso a paso sobre serializaci√≥n y persistencia en Python.

5. **StatQuest (YouTube)**  
   - https://www.youtube.com/c/joshstarmer  
   - Explicaciones visuales sobre modelos lineales y conceptos de machine learning.

---

### 5.3. Datasets de Pr√°ctica

1. **Scikit-learn Datasets:**  
   - Incluidos en la librer√≠a: `from sklearn import datasets`  
   - Ejemplos: `load_diabetes()`, `load_boston()`, `fetch_california_housing()`

2. **Kaggle Datasets:**  
   - https://www.kaggle.com/datasets  
   - Miles de datasets reales para probar modelos.

3. **UCI Machine Learning Repository:**  
   - https://archive.ics.uci.edu/ml/  
   - Datasets cl√°sicos para regresi√≥n, clasificaci√≥n y clustering.

---

### 5.4. Herramientas √ötiles

1. **Jupyter Notebook**  
   - Ideal para desarrollar y probar modelos de forma interactiva.  
   - Instalaci√≥n: `pip install jupyter`

2. **Google Colab**  
   - https://colab.research.google.com/  
   - Entorno online gratuito para ejecutar notebooks sin instalaci√≥n local.

3. **Anaconda Distribution**  
   - https://www.anaconda.com/  
   - Incluye Python, Jupyter y las principales librer√≠as cient√≠ficas.

4. **Visual Studio Code**  
   - https://code.visualstudio.com/  
   - Editor recomendado para proyectos Python con soporte Markdown integrado.

---
















